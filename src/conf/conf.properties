flume.rawdata.dir=/data/collect-data/total/rawdata

hdfs.dir=/user/hive/warehouse/rawdata/events2

flume.dispatch.dir=/data/collect-data/total/dispatch

flume.archive.rawdata.dir=/data/collect-data/total/archive/rawdata

flume.archive.dispatch.dir=/data/collect-data/total/archive/dispatch

local.backup.dir=/data/root/backup

hdfs.backup.dir=/user/hive/backup/rawdata

dispatch.file.maxlen=524288000

rollInterval=600

#load local file thread numbers
threadNum=32

#thread pool timeout (unit:hour)
timeout=10

#load file from today on a couple of days ahead
loadForwardDays=3

#delete data before a couple of days
delForwardDays=7

#hdfs compress file suffix
compress.suffix=.snappy

#compress class
compress.class=org.apache.hadoop.io.compress.SnappyCodec

hive.url=jdbc:hive://etl-1:10000/default
hive.driver=org.apache.hadoop.hive.jdbc.HiveDriver

hive.partition.hdfs=hdfs://nn-1:9000/user/hive/warehouse/rawdata/events2

hive.database.name=default
hive.table.name=events2

mail.send.username=
mail.send.password=
mail.receive.list=